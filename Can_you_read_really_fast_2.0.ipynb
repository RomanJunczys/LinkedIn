{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ec375a",
   "metadata": {},
   "source": [
    "# Can you read really fast?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5af80",
   "metadata": {},
   "source": [
    "#### Attention. Playing with the following script costs real money. Specifically, each request to OpenAI incurs a certain cost. Over two days of playing and testing, I spent \\\\$18 as part of the trial and then purchased access to ChatGPT Plus. I checked that summarizing a book by Jack London from 177,900 words to 1,782 (with creativity parameter 0.5) and to 1,807 words (with creativity parameter 0.0) costs \\\\$2.67.\n",
    "#### Summary - it was supposed to be at the end, but I am providing it now because I value your time.\n",
    "\n",
    "#### This was supposed to be a short and quick praise for how well OpenAI summarizes texts. During the few days of working on the script, I learned that:\n",
    "\n",
    "##### * it's not advisable to summarize favorite books, as the result can be comical or pathetic.\n",
    "##### * such summaries may be useful in business applications and can save a lot of time, especially when dealing with emails that are full of water or, worse, with friends who talk about nothing.\n",
    "\n",
    "\n",
    "##### Often it's the case that we don't have the time or desire to read a long text. Or we'd like to quickly find out what the text is about and whether it's worth our most valuable resource, which is time. And that's when artificial intelligence comes to the rescue, which helps us perfectly with a quick summary of the text.\n",
    "##### I have developed a system based on the ChatGPT language model, which summarizes long texts into shorter ones to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce97bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e6f22",
   "metadata": {},
   "source": [
    "##### I need a lengthy text. It would be great if this text is not only informative but also enjoyable to read and work with. I have found this kind of text.\n",
    "##### I chose this link for two reasons. Firstly, it is textual - which makes it safer for testing. Secondly, I really like the concept of the Gutenberg project.\n",
    "##### And in reality, I love this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ab8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gutenberg.org/cache/epub/215/pg215.txt'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    all_lengthy_text = response.content.decode('utf-8') # decode bytes to str    \n",
    "else:\n",
    "    print(f\"Failed to retrieve content from {url}. Response code: {response.status_code}\")\n",
    "\n",
    "# I am cutting the text about the Gutenberg project license, it won't be necessary for this example.\n",
    "all_lengthy_text = all_lengthy_text.split('*** START OF THE PROJECT GUTENBERG EBOOK THE CALL OF THE WILD ***')[1]\n",
    "all_lengthy_text = all_lengthy_text.split('*** END OF THE PROJECT GUTENBERG EBOOK THE CALL OF THE WILD ***')[0]\n",
    "\n",
    "# I am filtering empty lines\n",
    "def filter_empty_lines(text):\n",
    "    lines = text.split('\\n')\n",
    "    filtered_lines = [line for line in lines if line.strip()]\n",
    "    filtered_text = '\\n'.join(filtered_lines)\n",
    "    return filtered_text\n",
    "\n",
    "all_lengthy_text = filter_empty_lines(all_lengthy_text)\n",
    "\n",
    "all_words = len(all_lengthy_text)\n",
    "\n",
    "print(f'It is {len(all_lengthy_text)} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517c9b0",
   "metadata": {},
   "source": [
    "##### Time to launch the artificial intelligence. You will need your account on ChatGPT. Specifically, you will need your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run key.ipynb # I have stored my API key in this Jupyter notebook, but I understand the importance of securing sensitive information and will take steps to protect it.\n",
    "\n",
    "openai.api_key = api_key  # here enter your api key api_key = \"\"\n",
    "\n",
    "basic_page_words = 2000\n",
    "summary_factor = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c02cce",
   "metadata": {},
   "source": [
    "##### Below is the definition of the summarizing function for a single page, which is based on the number of words in the page. The maximum context length of this model is 4097 tokens. In this example, I will use 2000 words and a summary factor of less than half for every page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_page(page):\n",
    "    \n",
    "    page_length = len(page)\n",
    "    \n",
    "    prompt = f\"Please, summarizet his text for my 7 years old child : '{page}'\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine = 'text-davinci-003',\n",
    "        prompt = prompt,\n",
    "        max_tokens=int(len(page)*summary_factor),\n",
    "        n=1,    \n",
    "        temperature=0.0\n",
    "    )    \n",
    "    \n",
    "    summarize_page_length = len(response.choices[0].text)\n",
    "    \n",
    "    print(f'Page summarize facktor: {(summarize_page_length/page_length):.2f}\\n')\n",
    "    \n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9980c27",
   "metadata": {},
   "source": [
    "##### \tThis is a quick test for the first page (more precisely, for the first 2000 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_test = summarize_page(all_lengthy_text[0:basic_page_words])\n",
    "quick_test = filter_empty_lines(quick_test)\n",
    "print(f'{quick_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83add53",
   "metadata": {},
   "source": [
    "##### The way this function below works is by dividing a long text into portions of 2000 words and requesting an AI summary for each portion. The summarized pages are then combined to create a new summarized full text. The function performs summarization only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2acce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_once(text):\n",
    "    \n",
    "    all_words = len(text)\n",
    "    \n",
    "    start_word = 0\n",
    "    end_word = start_word + basic_page_words\n",
    "    \n",
    "    summarize_text = ''\n",
    "    \n",
    "    while end_word < all_words:    \n",
    "        \n",
    "        page = text[start_word:end_word]\n",
    "        \n",
    "        summarize = summarize_page(page)\n",
    "        summarize_text += summarize\n",
    "        \n",
    "        start_word += basic_page_words\n",
    "        end_word = start_word + basic_page_words\n",
    "        \n",
    "    summarize_text_length = len(summarize_text)\n",
    "    print(f'Real summarize factor is {(summarize_text_length/all_words):.2f}\\n')\n",
    "    \n",
    "    return summarize_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b2c1c",
   "metadata": {},
   "source": [
    "##### Finally, we continue to summarize the already summarized texts until we reach the desired size of the resulting text. For this example, I have set the summary length to one page, which is equivalent to 2000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_text = summarize_once(all_lengthy_text)\n",
    "summarized_text = filter_empty_lines(summarized_text)\n",
    "length = len(summarized_text)\n",
    "\n",
    "while length > 3 * basic_page_words:\n",
    "    text = summarized_text\n",
    "    summarized_text = summarize_once(text)\n",
    "    summarized_text = filter_empty_lines(summarized_text)\n",
    "    length = len(summarized_text)\n",
    "    print(f'length: {length}')\n",
    "\n",
    "summarized_text_length = len(summarized_text)\n",
    "print(f'Summarized text with abstract ratio {(summarized_text_length/all_words):.2f}: \\n\\n{summarized_text}')\n",
    "\n",
    "print(f'{len(summarized_text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ffcff0",
   "metadata": {},
   "source": [
    "##### Do you really want to know what came out? Well, then download this Jupyter notebook and run it for your OpenAI API. It's really great fun, especially when you start experimenting with your favorite book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f981bb7",
   "metadata": {},
   "source": [
    "##### Text summaries can be useful in various business areas such as:\n",
    "\n",
    "##### * Project management: Summaries can help quickly review project documents and assess project progress.\n",
    "##### * Human resources management: Summaries can help quickly understand resumes and cover letters of job candidates in the company.\n",
    "##### * Competitive analysis: Summaries can help effectively and quickly review competitor reports, making it easier to make strategic decisions.\n",
    "##### * Marketing: Summaries can help quickly review press articles, market reports, and analysis, making it easier to make marketing decisions.\n",
    "##### * Legal activities: Summaries can help quickly understand legal documents and agreements, making it easier to make business and legal decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266fb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
